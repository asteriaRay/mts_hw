{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ДЗ №7: двухвыборочные гипотезы (медианы и распределения) + бутстрап-проверка\n",
        "\n",
        "Датасет: **MovieLens 10M** (GroupLens) — логи взаимодействий пользователей (оценки фильмов во времени).  \n",
        "Мы заново загружаем данные, готовим признаки, сегментируем аудиторию и проверяем 4 гипотезы + 5-й пункт (бутстрап).\n",
        "\n",
        "**Метрики (как в прошлом ДЗ):**\n",
        "- `mean_rating` — средняя оценка пользователя\n",
        "- `median_rating` — медианная оценка пользователя\n",
        "- `share_high` — доля оценок ≥ 4\n",
        "- `unique_movies` — разнообразие (кол-во уникальных фильмов)\n",
        "\n",
        "> Но для требований текущего ДЗ нам достаточно выбрать **1 непрерывную** метрику и **1 дискретную** (если дискретной не было — создать).  \n",
        "> Здесь: непрерывная = `mean_rating`, дискретная = `unique_movies`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**0. Импорт и настройки**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.set_option(\"display.max_columns\", 50)\n",
        "pd.set_option(\"display.width\", 140)\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "rng = np.random.default_rng(RANDOM_STATE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**1. Загрузка логов (MovieLens 10M) и сэмплирование событий**\n",
        "\n",
        "В Colab удобно сразу брать подвыборку строк, чтобы не падать по памяти.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import io, zipfile, requests\n",
        "\n",
        "MOVIELENS_URL = \"https://files.grouplens.org/datasets/movielens/ml-10m.zip\"\n",
        "\n",
        "resp = requests.get(MOVIELENS_URL, stream=True)\n",
        "resp.raise_for_status()\n",
        "\n",
        "z = zipfile.ZipFile(io.BytesIO(resp.content))\n",
        "names = z.namelist()\n",
        "\n",
        "ratings_path = [p for p in names if p.endswith(\"/ratings.dat\")][0]\n",
        "\n",
        "with z.open(ratings_path) as f:\n",
        "    ratings = pd.read_csv(\n",
        "        f,\n",
        "        sep=\"::\",\n",
        "        engine=\"python\",\n",
        "        header=None,\n",
        "        names=[\"userId\", \"movieId\", \"rating\", \"timestamp\"],\n",
        "        dtype={\"userId\":\"int32\",\"movieId\":\"int32\",\"rating\":\"float32\",\"timestamp\":\"int64\"},\n",
        "    )\n",
        "\n",
        "# Сэмпл событий (регулируй при необходимости)\n",
        "N_EVENTS = 1_000_000\n",
        "ratings = ratings.sample(n=N_EVENTS, random_state=RANDOM_STATE).reset_index(drop=True)\n",
        "\n",
        "ratings.head(), ratings.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**2. Подготовка пользовательских метрик (user-level)**\n",
        "\n",
        "Считаем метрики на уровне пользователя, чтобы потом сравнивать сегменты статистическими тестами.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "user = ratings.groupby(\"userId\", sort=False).agg(\n",
        "    n_events=(\"movieId\", \"size\"),\n",
        "    mean_rating=(\"rating\", \"mean\"),\n",
        "    median_rating=(\"rating\", \"median\"),\n",
        "    share_high=(\"rating\", lambda x: float(np.mean(x >= 4.0))),\n",
        "    unique_movies=(\"movieId\", \"nunique\"),\n",
        ").reset_index()\n",
        "\n",
        "user.head(), user.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**3. Сегментация аудитории**\n",
        "\n",
        "Разобьем пользователей на 3 сегмента по активности (`n_events`) — tertiles:\n",
        "- Light (мало событий)\n",
        "- Medium\n",
        "- Heavy (много событий)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q1, q2 = user[\"n_events\"].quantile([1/3, 2/3]).to_list()\n",
        "\n",
        "def segment(n):\n",
        "    if n <= q1:\n",
        "        return \"Light\"\n",
        "    elif n <= q2:\n",
        "        return \"Medium\"\n",
        "    return \"Heavy\"\n",
        "\n",
        "user[\"segment\"] = user[\"n_events\"].apply(segment)\n",
        "user[\"segment\"].value_counts()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**4. Выбор двух групп для двухвыборочных гипотез**\n",
        "\n",
        "Будем сравнивать наиболее контрастные сегменты: **Light vs Heavy**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "A, B = \"Light\", \"Heavy\"\n",
        "dfA = user[user[\"segment\"] == A].copy()\n",
        "dfB = user[user[\"segment\"] == B].copy()\n",
        "\n",
        "print(\"Users in A:\", len(dfA), \"Users in B:\", len(dfB))\n",
        "dfA[[\"n_events\",\"mean_rating\",\"unique_movies\"]].head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## **Пункт 1. Сформировать 4 двухвыборочные гипотезы (медианы и распределения) для дискретного и непрерывного случая**\n",
        "\n",
        "Выбираем:\n",
        "- **Непрерывная** метрика: `mean_rating`\n",
        "- **Дискретная** метрика: `unique_movies`\n",
        "\n",
        "**(1) Непрерывная, медианы (`mean_rating`)**  \n",
        "- H0: `median(mean_rating)_Light = median(mean_rating)_Heavy`  \n",
        "- H1: медианы различаются\n",
        "\n",
        "**(2) Непрерывная, распределения (`mean_rating`)**  \n",
        "- H0: распределения `mean_rating` одинаковы в Light и Heavy  \n",
        "- H1: распределения различаются\n",
        "\n",
        "**(3) Дискретная, медианы (`unique_movies`)**  \n",
        "- H0: `median(unique_movies)_Light = median(unique_movies)_Heavy`  \n",
        "- H1: медианы различаются\n",
        "\n",
        "**(4) Дискретная, распределения (`unique_movies`)**  \n",
        "- H0: распределения `unique_movies` одинаковы в Light и Heavy  \n",
        "- H1: распределения различаются\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## **Пункт 2. Проверить каждую гипотезу релевантным тестом + обосновать выбор**\n",
        "\n",
        "**Почему именно такие тесты:**\n",
        "- Для **медиан** используем **Mood’s median test** (`scipy.stats.median_test`): это прямой тест равенства медиан, подходит для 2 независимых выборок, не требует нормальности.\n",
        "- Для **распределений**:\n",
        "  - непрерывное: **KS 2-sample** (Kolmogorov–Smirnov), сравнивает CDF и проверяет равенство распределений целиком;\n",
        "  - дискретное: **χ² тест однородности** по таблице частот (для устойчивости используем биннинг).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **2.1. Тест для гипотезы (1): медианы `mean_rating`**\n",
        "Тест: **Mood’s median test**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = dfA[\"mean_rating\"].dropna().to_numpy()\n",
        "y = dfB[\"mean_rating\"].dropna().to_numpy()\n",
        "\n",
        "med_stat, med_p, grand_median, table = stats.median_test(x, y, ties=\"below\")\n",
        "\n",
        "{\n",
        "    \"metric\": \"mean_rating\",\n",
        "    \"median_A\": float(np.median(x)),\n",
        "    \"median_B\": float(np.median(y)),\n",
        "    \"grand_median\": float(grand_median),\n",
        "    \"p_value\": float(med_p),\n",
        "    \"table_2x2\": table.tolist()\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **2.2. Тест для гипотезы (2): распределения `mean_rating`**\n",
        "Тест: **KS 2-sample**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ks_cont = stats.ks_2samp(x, y, alternative=\"two-sided\", method=\"asymp\")\n",
        "{\"metric\": \"mean_rating\", \"KS_stat\": float(ks_cont.statistic), \"p_value\": float(ks_cont.pvalue)}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **2.3. Тест для гипотезы (3): медианы `unique_movies`**\n",
        "Тест: **Mood’s median test**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_d = dfA[\"unique_movies\"].dropna().to_numpy()\n",
        "y_d = dfB[\"unique_movies\"].dropna().to_numpy()\n",
        "\n",
        "med_stat_d, med_p_d, grand_median_d, table_d = stats.median_test(x_d, y_d, ties=\"below\")\n",
        "\n",
        "{\n",
        "    \"metric\": \"unique_movies\",\n",
        "    \"median_A\": float(np.median(x_d)),\n",
        "    \"median_B\": float(np.median(y_d)),\n",
        "    \"grand_median\": float(grand_median_d),\n",
        "    \"p_value\": float(med_p_d),\n",
        "    \"table_2x2\": table_d.tolist()\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **2.4. Тест для гипотезы (4): распределения `unique_movies`**\n",
        "Тест: **χ² тест однородности** по бинированным значениям (частоты по категориям)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Биннинг, чтобы не было слишком редких категорий (и чтобы expected частоты были разумные)\n",
        "bins = [0, 5, 10, 20, 40, 80, 160, np.inf]\n",
        "labels = [\"1-5\",\"6-10\",\"11-20\",\"21-40\",\"41-80\",\"81-160\",\"160+\"]\n",
        "\n",
        "A_cat = pd.cut(dfA[\"unique_movies\"], bins=bins, labels=labels, include_lowest=True).astype(\"object\")\n",
        "B_cat = pd.cut(dfB[\"unique_movies\"], bins=bins, labels=labels, include_lowest=True).astype(\"object\")\n",
        "\n",
        "ct = pd.crosstab(\n",
        "    pd.Series([A]*len(A_cat) + [B]*len(B_cat), name=\"group\"),\n",
        "    pd.Series(pd.concat([A_cat, B_cat], ignore_index=True), name=\"unique_movies_bin\")\n",
        ")\n",
        "\n",
        "ct\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "chi2_stat, chi2_p, dof, expected = stats.chi2_contingency(ct.values)\n",
        "\n",
        "{\n",
        "    \"metric\": \"unique_movies (binned)\",\n",
        "    \"chi2\": float(chi2_stat),\n",
        "    \"dof\": int(dof),\n",
        "    \"p_value\": float(chi2_p),\n",
        "    \"min_expected\": float(np.min(expected)),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## **Пункт 2 (5-й пункт). Проверка результатов с бутстрапом**\n",
        "\n",
        "Сделаем “бутстрап под H0” (null bootstrap):  \n",
        "- объединяем две группы в один pool (это модель H0: группы из одного распределения),  \n",
        "- **семплируем с возвращением** две выборки размеров `len(A)` и `len(B)`,  \n",
        "- считаем статистику (разность медиан / KS / χ²),  \n",
        "- p-value = доля бутстрап-статистик, которые по модулю ≥ наблюдаемой.\n",
        "\n",
        "Это дает сравнимую с тестами проверку без асимптотических допущений (но вычислительно дороже).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def null_bootstrap_pvalue(x, y, stat_fn, B=400, seed=42):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    x = np.asarray(x); y = np.asarray(y)\n",
        "    n_x, n_y = len(x), len(y)\n",
        "    pooled = np.concatenate([x, y])\n",
        "\n",
        "    obs = float(stat_fn(x, y))\n",
        "    boot = np.empty(B, dtype=float)\n",
        "    for b in range(B):\n",
        "        xb = rng.choice(pooled, size=n_x, replace=True)\n",
        "        yb = rng.choice(pooled, size=n_y, replace=True)\n",
        "        boot[b] = stat_fn(xb, yb)\n",
        "\n",
        "    p = (np.sum(np.abs(boot) >= abs(obs)) + 1) / (B + 1)  # two-sided\n",
        "    return obs, float(p), boot\n",
        "\n",
        "# Статистика 1: разность медиан\n",
        "stat_median_diff = lambda a,b: np.median(a) - np.median(b)\n",
        "\n",
        "# Статистика 2: KS\n",
        "stat_ks = lambda a,b: stats.ks_2samp(a, b, alternative=\"two-sided\", method=\"asymp\").statistic\n",
        "\n",
        "# Статистика 3: chi2 по бинам\n",
        "def stat_chi2_bins(a, b):\n",
        "    a_cat = pd.cut(a, bins=bins, labels=labels, include_lowest=True)\n",
        "    b_cat = pd.cut(b, bins=bins, labels=labels, include_lowest=True)\n",
        "    bins_series = pd.concat([pd.Series(a_cat), pd.Series(b_cat)], ignore_index=True)\n",
        "    ct_local = pd.crosstab(\n",
        "        pd.Series([0]*len(a_cat) + [1]*len(b_cat), name='group'),\n",
        "        pd.Series(bins_series, name='bin')\n",
        "    )\n",
        "    # Выкидываем бины, которые отсутствуют в обеих группах (иначе ожидаемые частоты могут стать 0)\n",
        "    col_sums = ct_local.sum(axis=0)\n",
        "    ct_local = ct_local.loc[:, col_sums > 0]\n",
        "    # Если после фильтрации осталась одна колонка, статистика = 0 (распределения тривиально одинаковы по бинам)\n",
        "    if ct_local.shape[1] <= 1:\n",
        "        return 0.0\n",
        "    chi2_stat, _, _, expected = stats.chi2_contingency(ct_local.values)\n",
        "    # На всякий случай: если всё равно есть нули в expected (редко), добавим маленький псевдосчет\n",
        "    if np.any(expected == 0):\n",
        "        ct_eps = ct_local.values.astype(float) + 1e-6\n",
        "        chi2_stat = stats.chi2_contingency(ct_eps)[0]\n",
        "    return float(chi2_stat)\n",
        "\n",
        "B_BOOT = 300  # держим маленьким для Colab\n",
        "\n",
        "# (1) mean_rating median\n",
        "obs_mr_med, p_mr_med, _ = null_bootstrap_pvalue(x, y, stat_median_diff, B=B_BOOT, seed=RANDOM_STATE)\n",
        "\n",
        "# (2) mean_rating distr (KS)\n",
        "obs_mr_ks, p_mr_ks, _ = null_bootstrap_pvalue(x, y, stat_ks, B=B_BOOT, seed=RANDOM_STATE)\n",
        "\n",
        "# (3) unique_movies median\n",
        "obs_um_med, p_um_med, _ = null_bootstrap_pvalue(x_d, y_d, stat_median_diff, B=B_BOOT, seed=RANDOM_STATE)\n",
        "\n",
        "# (4) unique_movies distr (chi2)\n",
        "obs_um_chi2, p_um_chi2, _ = null_bootstrap_pvalue(x_d, y_d, stat_chi2_bins, B=B_BOOT, seed=RANDOM_STATE)\n",
        "\n",
        "bootstrap_results = pd.DataFrame([\n",
        "    [\"Median(mean_rating)\", obs_mr_med, p_mr_med],\n",
        "    [\"Distr(mean_rating) KS\", obs_mr_ks, p_mr_ks],\n",
        "    [\"Median(unique_movies)\", obs_um_med, p_um_med],\n",
        "    [\"Distr(unique_movies) chi2\", obs_um_chi2, p_um_chi2],\n",
        "], columns=[\"Hypothesis\",\"obs_stat\",\"bootstrap_pvalue\"])\n",
        "\n",
        "bootstrap_results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## **Пункт 3. Сравнение результатов (пункты 2.1–2.4) с бутстрапом и объяснение различий**\n",
        "\n",
        "Соберем p-value классических тестов и бутстрапа в одну таблицу.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "alpha = 0.05\n",
        "\n",
        "classic_results = pd.DataFrame([\n",
        "    [\"Median(mean_rating)\", float(med_p)],\n",
        "    [\"Distr(mean_rating) KS\", float(ks_cont.pvalue)],\n",
        "    [\"Median(unique_movies)\", float(med_p_d)],\n",
        "    [\"Distr(unique_movies) chi2\", float(chi2_p)],\n",
        "], columns=[\"Hypothesis\",\"p_value_test\"])\n",
        "\n",
        "out = classic_results.merge(bootstrap_results[[\"Hypothesis\",\"bootstrap_pvalue\"]], on=\"Hypothesis\", how=\"left\")\n",
        "out[\"reject_test_0.05\"] = out[\"p_value_test\"] < alpha\n",
        "out[\"reject_bootstrap_0.05\"] = out[\"bootstrap_pvalue\"] < alpha\n",
        "out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Как интерпретировать расхождения (если они есть):**\n",
        "- Бутстрап здесь “под H0” и численно приближает нулевое распределение статистики; при больших выборках результаты обычно совпадают с асимптотическими тестами.\n",
        "- Если отличаются:\n",
        "  - бутстрап может быть шумным при малом числе итераций (`B_BOOT`),\n",
        "  - χ² зависит от биннинга (теряем часть информации),\n",
        "  - Mood’s median test использует только информацию “выше/ниже медианы”, и может вести себя иначе, чем бутстрап по разности медиан.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## **Пункт 4. Какой подход мощнее в конкретном случае и почему**\n",
        "\n",
        "Сравниваем “классические тесты” vs “бутстрап-проверку” (и немного — какие статистики вообще сильнее).\n",
        "\n",
        "**В этом кейсе (очень большие выборки пользователей):**\n",
        "- Асимптотические тесты (Mood’s median test, KS, χ²) обычно **мощные и стабильные**: p-value считается быстро и точно.\n",
        "- Бутстрап “под H0” при достаточном числе итераций даёт близкий результат, но:\n",
        "  - требует больше вычислений,\n",
        "  - добавляет Monte-Carlo погрешность (особенно при малом `B_BOOT`).\n",
        "\n",
        "**По мощности статистик:**\n",
        "- Для “различия типичного уровня” часто мощнее тесты, использующие больше информации (например, Mann–Whitney), чем строгий тест медиан (Mood’s median test).\n",
        "- Однако в задании просили гипотезы именно про **медианы**, поэтому Mood’s median test — самый прямой.\n",
        "\n",
        "Ниже — быстрая *эмпирическая* иллюстрация: как часто тест отвергает H0 на подвыборках фиксированного размера (это не обязательно, но помогает аргументировать).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def estimate_reject_rate(x_full, y_full, pvalue_fn, n=400, n_trials=60, alpha=0.05, seed=7):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    rej = 0\n",
        "    for _ in range(n_trials):\n",
        "        xs = rng.choice(x_full, size=n, replace=True)\n",
        "        ys = rng.choice(y_full, size=n, replace=True)\n",
        "        p = pvalue_fn(xs, ys)\n",
        "        if p < alpha:\n",
        "            rej += 1\n",
        "    return rej / n_trials\n",
        "\n",
        "# p-value через Mood's median test\n",
        "def p_median_test(a, b):\n",
        "    _, p, _, _ = stats.median_test(a, b, ties=\"below\")\n",
        "    return p\n",
        "\n",
        "# p-value через null bootstrap по разности медиан (меньше B для скорости)\n",
        "def p_bootstrap_median(a, b):\n",
        "    _, p, _ = null_bootstrap_pvalue(a, b, stat_median_diff, B=200, seed=RANDOM_STATE)\n",
        "    return p\n",
        "\n",
        "rate_median_test = estimate_reject_rate(x, y, p_median_test, n=350, n_trials=40, alpha=0.05, seed=1)\n",
        "rate_bootstrap = estimate_reject_rate(x, y, p_bootstrap_median, n=350, n_trials=20, alpha=0.05, seed=2)\n",
        "\n",
        "{\"reject_rate_median_test_mean_rating\": rate_median_test,\n",
        " \"reject_rate_bootstrap_median_mean_rating\": rate_bootstrap}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Вывод:**  \n",
        "- В больших выборках “классические” тесты обычно дают стабильные результаты и не требуют тяжелых вычислений.  \n",
        "- Бутстрап хорош как проверка устойчивости, но при ограниченном числе итераций может быть шумнее.  \n",
        "- Если сравнивать по мощности “под задачу”: тесты, использующие больше информации (ранги/вся CDF/частоты), чаще мощнее, чем тесты по одной характеристике.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Дополнительно: коробка с усами\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'x' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m     plt\u001b[38;5;241m.\u001b[39mgrid(\u001b[38;5;28;01mTrue\u001b[39;00m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m)\n\u001b[0;32m      6\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m----> 8\u001b[0m boxplot_two_groups(\u001b[43mx\u001b[49m, y, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_rating (user-level)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m boxplot_two_groups(x_d, y_d, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munique_movies (user-level)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
          ]
        }
      ],
      "source": [
        "def boxplot_two_groups(valuesA, valuesB, title):\n",
        "    plt.figure(figsize=(7,4))\n",
        "    plt.boxplot([valuesA, valuesB], labels=[A, B], showfliers=False)\n",
        "    plt.title(title)\n",
        "    plt.grid(True, axis=\"y\", alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "boxplot_two_groups(x, y, \"mean_rating (user-level)\")\n",
        "boxplot_two_groups(x_d, y_d, \"unique_movies (user-level)\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
